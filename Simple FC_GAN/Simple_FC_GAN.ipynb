{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJxpQzqHBB-K"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59OlTbAWBEMM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaDGHSB5BI9d"
      },
      "source": [
        "# Creating the Generator network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gl9w40udCCF2"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super().__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            nn.Linear(in_features, 128),\n",
        "            nn.LeakyReLU(0.01),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.disc(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etda90daB3eT"
      },
      "source": [
        "# Creating the Discriminator network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1djkUONKCClO"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, img_dim):\n",
        "        super().__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),\n",
        "            nn.LeakyReLU(0.01),\n",
        "            nn.Linear(256, img_dim),\n",
        "            nn.Tanh(),  # normalize inputs to [-1, 1] so make outputs [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gen(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-Ic1XimCKV0"
      },
      "source": [
        "# Hyperparameters Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQbwhQt_CUMv"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "lr = 3e-4\n",
        "z_dim = 64\n",
        "image_dim = 28 * 28 * 1  # 784\n",
        "batch_size = 32\n",
        "num_epochs = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlvMM5F1C5yE"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMz_GHKoC_al"
      },
      "source": [
        "# Initializing Discriminator and Generator networks\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDr9sRQiCYXv"
      },
      "outputs": [],
      "source": [
        "disc = Discriminator(image_dim).to(device)\n",
        "gen = Generator(z_dim, image_dim).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Z67McXDVHA"
      },
      "source": [
        "# Creating fixed noise input for the Generator and Preparing image transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIysg-PbDVbp"
      },
      "outputs": [],
      "source": [
        "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
        "transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,)),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKEOrm_cDmwS"
      },
      "source": [
        "# Data Loading Optimizer Initialization, Loss Function Declaration and Initialize Summary Writer for TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-82y8vyCbx6"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
        "criterion = nn.BCELoss()\n",
        "writer_fake = SummaryWriter(f\"logs/fake\")\n",
        "writer_real = SummaryWriter(f\"logs/real\")\n",
        "step = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG-YKIGoD33h"
      },
      "source": [
        "# Training The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YBOp0khCiZX"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (real, _) in enumerate(loader):\n",
        "        real = real.view(-1, 784).to(device)\n",
        "        batch_size = real.shape[0]\n",
        "\n",
        "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
        "        noise = torch.randn(batch_size, z_dim).to(device)\n",
        "        fake = gen(noise)\n",
        "        disc_real = disc(real).view(-1)\n",
        "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
        "        disc_fake = disc(fake).view(-1)\n",
        "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "        lossD = (lossD_real + lossD_fake) / 2\n",
        "        disc.zero_grad()\n",
        "        lossD.backward(retain_graph=True)\n",
        "        opt_disc.step()\n",
        "\n",
        "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
        "        # where the second option of maximizing doesn't suffer from\n",
        "        # saturating gradients\n",
        "        output = disc(fake).view(-1)\n",
        "        lossG = criterion(output, torch.ones_like(output))\n",
        "        gen.zero_grad()\n",
        "        lossG.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "        if batch_idx == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
        "                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n",
        "                data = real.reshape(-1, 1, 28, 28)\n",
        "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
        "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
        "\n",
        "                writer_fake.add_image(\n",
        "                    \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
        "                )\n",
        "                writer_real.add_image(\n",
        "                    \"Mnist Real Images\", img_grid_real, global_step=step\n",
        "                )\n",
        "                step += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqjXGx9QI9hg"
      },
      "outputs": [],
      "source": [
        "writer_fake.close()\n",
        "writer_real.close()\n",
        "%load_ext tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aNh4IP7JDU_",
        "outputId": "248a9daf-c87b-4ce4-aa12-f71c21ddbd23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-02 15:46:46.004809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.12.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!tensorboard --logdir runs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7UPG1J0Ih1c",
        "outputId": "cd8fca67-8f5b-48b1-f5d2-cc554f398035"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-02 15:48:08.322435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
            "the following directory:\n",
            "\n",
            "logs\n",
            "\n",
            "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
            "data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) yes\n",
            "\n",
            "To sign in with the TensorBoard uploader:\n",
            "\n",
            "1. On your computer or phone, visit:\n",
            "\n",
            "   https://www.google.com/device\n",
            "\n",
            "2. Sign in with your Google account, then enter:\n",
            "\n",
            "   ZCX-XMJ-WSP\n",
            "\n",
            "\n",
            "Upload started and will continue reading any new data as it's added to the logdir.\n",
            "\n",
            "To stop uploading, press Ctrl-C.\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/UyBoOzAoTeqaf09yQKf5KQ/\n",
            "\n",
            "\u001b[1m[2023-05-02T15:49:56]\u001b[0m Started scanning logdir.\n",
            "\n",
            "\n",
            "Interrupted.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
            "    sys.exit(run_main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/main.py\", line 46, in run_main\n",
            "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/program.py\", line 276, in main\n",
            "    return runner(self.flags) or 0\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/uploader/uploader_subcommand.py\", line 691, in run\n",
            "    return _run(flags, self._experiment_url_callback)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/uploader/uploader_subcommand.py\", line 123, in _run\n",
            "    with channel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\", line 1746, in __exit__\n",
            "    self._close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\", line 1732, in _close\n",
            "    self._channel.close(cygrpc.StatusCode.cancelled, 'Channel closed!')\n",
            "  File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 513, in grpc._cython.cygrpc.Channel.close\n",
            "  File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 399, in grpc._cython.cygrpc._close\n",
            "  File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 429, in grpc._cython.cygrpc._close\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 389, in notify_all\n",
            "    def notify_all(self):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!tensorboard dev upload --logdir logs \\\n",
        "--name \"My latest experiment\" \\\n",
        "--description \"Simple comparison of several hyperparameters\"\n",
        "     "
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}